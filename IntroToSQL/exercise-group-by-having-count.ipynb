{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**This notebook is an exercise in the [SQL](https://www.kaggle.com/learn/intro-to-sql) course.  You can reference the tutorial at [this link](https://www.kaggle.com/dansbecker/group-by-having-count).**\n\n---\n","metadata":{}},{"cell_type":"markdown","source":"# Introduction\n\nQueries with **GROUP BY** can be powerful. There are many small things that can trip you up (like the order of the clauses), but it will start to feel natural once you've done it a few times. Here, you'll write queries using **GROUP BY** to answer questions from the Hacker News dataset.\n\nBefore you get started, run the following cell to set everything up:","metadata":{}},{"cell_type":"code","source":"# Set up feedback system\n#from learntools.core import binder\n#binder.bind(globals())\n#from learntools.sql.ex3 import *\n#print(\"Setup Complete\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Hack to get setup code to work\n# USE 'FULL' INSTEAD OF 'COMMENTS' FOR TABLE NAME THROUGHOUT EXCERCISE !\n\n#Set up feedback system\nfrom learntools.core import binder\nbinder.bind(globals())\n\nwith open(\"/opt/conda/lib/python3.10/site-packages/learntools/sql/ex3.py\",\"r\") as f:\n    ex3 = f.read()\n    ex3 = ex3.replace(\"SELECT author\",\"SELECT `by`\") # need to use backtick since column name is 'by' which is also a SQL keyword\n    ex3 = ex3.replace(\"GROUP BY author\",\"GROUP BY `by`\")\n    ex3 = ex3.replace(\"\\'author\\'\",\"\\'by\\'\")\n    ex3 = ex3.replace(\"`author`\",\"\\`by\\`\")\n    ex3 = ex3.replace(\"bigquery-public-data.hacker_news.comments\",\"bigquery-public-data.hacker_news.full\")\n\n    #Write fixes into v2 file\n    with open(\"/opt/conda/lib/python3.10/site-packages/learntools/sql/ex3_v2.py\",\"w\") as f2:\n        f2.write(ex3)\n\n#Import v2\nfrom learntools.sql.ex3_v2 import *\nprint(\"Setup Complete\")","metadata":{"execution":{"iopub.status.busy":"2023-10-01T23:45:50.482380Z","iopub.execute_input":"2023-10-01T23:45:50.482815Z","iopub.status.idle":"2023-10-01T23:45:56.537016Z","shell.execute_reply.started":"2023-10-01T23:45:50.482782Z","shell.execute_reply":"2023-10-01T23:45:56.536040Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The code cell below fetches the `comments` table from the `hacker_news` dataset.  We also preview the first five rows of the table.","metadata":{}},{"cell_type":"markdown","source":"**Replaced table_ref = dataset_ref.table(\"comments\") with table_ref = dataset_ref.table(\"full\") in the code below**","metadata":{}},{"cell_type":"code","source":"from google.cloud import bigquery\n\n# Create a \"Client\" object\nclient = bigquery.Client()\n\n# Construct a reference to the \"hacker_news\" dataset\ndataset_ref = client.dataset(\"hacker_news\", project=\"bigquery-public-data\")\n\n# API request - fetch the dataset\ndataset = client.get_dataset(dataset_ref)\n\n# Construct a reference to the \"comments\" table\ntable_ref = dataset_ref.table(\"full\") # comments\n\n# API request - fetch the table\ntable = client.get_table(table_ref)\n\n# Preview the first five lines of the \"comments\" table\nclient.list_rows(table, max_results=5).to_dataframe()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T23:46:18.276749Z","iopub.execute_input":"2023-10-01T23:46:18.277894Z","iopub.status.idle":"2023-10-01T23:46:19.970539Z","shell.execute_reply.started":"2023-10-01T23:46:18.277856Z","shell.execute_reply":"2023-10-01T23:46:19.969482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Exercises\n\n### 1) Prolific commenters\n\nHacker News would like to send awards to everyone who has written more than 10,000 posts. Write a query that returns all authors with more than 10,000 posts as well as their post counts. Call the column with post counts `NumPosts`.\n\nIn case sample query is helpful, here is a query you saw in the tutorial to answer a similar question:\n```\nquery = \"\"\"\n        SELECT parent, COUNT(1) AS NumPosts\n        FROM `bigquery-public-data.hacker_news.comments`\n        GROUP BY parent\n        HAVING COUNT(1) > 10\n        \"\"\"\n```","metadata":{}},{"cell_type":"code","source":"# Query to select prolific commenters and post counts\nprolific_commenters_query = \"\"\"\n                            SELECT `by`, COUNT(1) AS NumPosts\n                            FROM `bigquery-public-data.hacker_news.full`\n                            GROUP BY `by`\n                            HAVING COUNT(1) > 10000\n                            \"\"\"# Your code goes here\n\n# Set up the query (cancel the query if it would use too much of \n# your quota, with the limit set to 1 GB)\nsafe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\nquery_job = client.query(prolific_commenters_query, job_config=safe_config)\n\n# API request - run the query, and return a pandas DataFrame\nprolific_commenters = query_job.to_dataframe()\n\n# View top few rows of results\nprint(prolific_commenters.head())\n\n# Check your answer\nq_1.check()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T23:50:38.733657Z","iopub.execute_input":"2023-10-01T23:50:38.734005Z","iopub.status.idle":"2023-10-01T23:50:40.602064Z","shell.execute_reply.started":"2023-10-01T23:50:38.733979Z","shell.execute_reply":"2023-10-01T23:50:40.601034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For the solution, uncomment the line below.","metadata":{}},{"cell_type":"code","source":"#q_1.solution()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T23:50:49.656611Z","iopub.execute_input":"2023-10-01T23:50:49.657251Z","iopub.status.idle":"2023-10-01T23:50:49.661365Z","shell.execute_reply.started":"2023-10-01T23:50:49.657221Z","shell.execute_reply":"2023-10-01T23:50:49.660354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2) Deleted comments\n\nHow many comments have been deleted? (If a comment was deleted, the `deleted` column in the comments table will have the value `True`.)","metadata":{}},{"cell_type":"code","source":"# Write your query here and figure out the answer\n\n# Query to select How many comments have been deleted\nprolific_commenters_query = \"\"\"\n                            SELECT COUNT(1) AS DelPosts\n                            FROM `bigquery-public-data.hacker_news.full`\n                            WHERE `deleted` = True\n                            \"\"\"# Your code goes here\n\n# Set up the query (cancel the query if it would use too much of \n# your quota, with the limit set to 1 GB)\nsafe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\nquery_job = client.query(prolific_commenters_query, job_config=safe_config)\n\n# API request - run the query, and return a pandas DataFrame\nprolific_commenters = query_job.to_dataframe()\n\n# View top few rows of results\nprint(prolific_commenters.head())\n","metadata":{"execution":{"iopub.status.busy":"2023-10-01T23:59:22.553148Z","iopub.execute_input":"2023-10-01T23:59:22.554161Z","iopub.status.idle":"2023-10-01T23:59:24.364377Z","shell.execute_reply.started":"2023-10-01T23:59:22.554113Z","shell.execute_reply":"2023-10-01T23:59:24.363386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_deleted_posts = 968172 # Put your answer here\n\n# Check your answer\nq_2.check()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T23:59:45.392202Z","iopub.execute_input":"2023-10-01T23:59:45.392620Z","iopub.status.idle":"2023-10-01T23:59:45.402290Z","shell.execute_reply.started":"2023-10-01T23:59:45.392587Z","shell.execute_reply":"2023-10-01T23:59:45.401241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For the solution, uncomment the line below.","metadata":{}},{"cell_type":"code","source":"#q_2.solution()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T23:59:57.051273Z","iopub.execute_input":"2023-10-01T23:59:57.051631Z","iopub.status.idle":"2023-10-01T23:59:57.055534Z","shell.execute_reply.started":"2023-10-01T23:59:57.051605Z","shell.execute_reply":"2023-10-01T23:59:57.054504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Keep Going\n**[Click here](https://www.kaggle.com/dansbecker/order-by)** to move on and learn about the **ORDER BY** clause.","metadata":{}},{"cell_type":"markdown","source":"---\n\n\n\n\n*Have questions or comments? Visit the [course discussion forum](https://www.kaggle.com/learn/intro-to-sql/discussion) to chat with other learners.*","metadata":{}}]}